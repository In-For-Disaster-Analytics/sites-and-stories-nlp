{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peremartra/Large-Language-Model-Notebooks-Course/blob/main/P1-NL2SQL/nl2sql_prompt_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c23b4dd1",
      "metadata": {
        "id": "c23b4dd1"
      },
      "source": [
        "<div align=\"center\">\n",
        "<h1><a href=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course\">Learn by Doing LLM Projects</a></h1>\n",
        "    <h3>Understand And Apply Large Language Models</h3>\n",
        "    <h2>Natural Language to SQL with LLMs</h2>\n",
        "    <h3>Create a prompt to generate SQL with OpenAI Models</h3>\n",
        "    by <b>Pere Martra</b>\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "<div align=\"center\">\n",
        "    &nbsp;\n",
        "    <a target=\"_blank\" href=\"https://www.linkedin.com/in/pere-martra/\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social\"></a>\n",
        "    \n",
        "</div>\n",
        "\n",
        "<br>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d930c89-4954-4e39-be5a-601c1dd89512",
      "metadata": {
        "id": "7d930c89-4954-4e39-be5a-601c1dd89512"
      },
      "source": [
        "In one of the [first lessons in the course](https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/1-Introduction%20to%20LLMs%20with%20OpenAI/nl2sql.ipynb), we did a Natural Language to SQL Generator using the OpenAI API. It works relatively fine, but the prompt was built in a basic style.\n",
        "\n",
        "Now we are going to rebuild the prompt following the instructions in a paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a1d00720",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1d00720",
        "outputId": "3e19319f-63d5-4f9b-8863-c77f7dfec321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.1.1\n",
            "  Downloading openai-1.1.1-py3-none-any.whl (217 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.8/217.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.1.1) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.1.1) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.1.1)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.1.1) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.1.1) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai==1.1.1) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.1.1) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.1.1) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.1.1) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.1.1) (2023.7.22)\n",
            "Collecting httpcore (from httpx<1,>=0.23.0->openai==1.1.1)\n",
            "  Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai==1.1.1)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.1 httpx-0.25.1 openai-1.1.1\n"
          ]
        }
      ],
      "source": [
        "#First install the OpenAI library to acces gpt-3.5-turbo model.\n",
        "!pip install openai==1.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a03f026a",
      "metadata": {
        "id": "a03f026a"
      },
      "outputs": [],
      "source": [
        "#You need an OpenAI key in order to use the OpenAI API https://platform.openai.com/account/api-keys\n",
        "\n",
        "import openai\n",
        "openai.api_key='your-opeai-api-key'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a05b80-88fd-42b2-ba89-763074ae74e9",
      "metadata": {
        "id": "53a05b80-88fd-42b2-ba89-763074ae74e9"
      },
      "source": [
        "## The old Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "922f8d24",
      "metadata": {
        "id": "922f8d24"
      },
      "outputs": [],
      "source": [
        "#The old prompt\n",
        "old_context = [ {'role':'system', 'content':\"\"\"\n",
        "you are a bot to assist in create SQL commands, all your answers should start with \\\n",
        "this is your SQL, and after that an SQL that can do what the user request. \\\n",
        "Your Database is composed by a SQL database with some tables. \\\n",
        "Try to Maintain the SQL order simple.\n",
        "Put the SQL command in white letters with a black background, and just after \\\n",
        "a simple and concise text explaining how it works.\n",
        "If the user ask for something that can not be solved with an SQL Order \\\n",
        "just answer something nice and simple, maximum 10 words, asking him for something that \\\n",
        "can be solved with SQL.\n",
        "\"\"\"} ]\n",
        "\n",
        "old_context.append( {'role':'system', 'content':\"\"\"\n",
        "first table:\n",
        "{\n",
        "  \"tableName\": \"employees\",\n",
        "  \"fields\": [\n",
        "    {\n",
        "      \"nombre\": \"ID_usr\",\n",
        "      \"tipo\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"nombre\": \"name\",\n",
        "      \"tipo\": \"varchar\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\"\n",
        "})\n",
        "\n",
        "old_context.append( {'role':'system', 'content':\"\"\"\n",
        "second table:\n",
        "{\n",
        "  \"tableName\": \"salary\",\n",
        "  \"fields\": [\n",
        "    {\n",
        "      \"nombre\": \"ID_usr\",\n",
        "      \"type\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"year\",\n",
        "      \"type\": \"date\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"salary\",\n",
        "      \"type\": \"float\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\"\n",
        "})\n",
        "\n",
        "old_context.append( {'role':'system', 'content':\"\"\"\n",
        "third table:\n",
        "{\n",
        "  \"tablename\": \"studies\",\n",
        "  \"fields\": [\n",
        "    {\n",
        "      \"name\": \"ID\",\n",
        "      \"type\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"ID_usr\",\n",
        "      \"type\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"educational_level\",\n",
        "      \"type\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Institution\",\n",
        "      \"type\": \"varchar\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Years\",\n",
        "      \"type\": \"date\"\n",
        "    }\n",
        "    {\n",
        "      \"name\": \"Speciality\",\n",
        "      \"type\": \"varchar\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\"\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "377acaae-7dd0-4d13-bc68-9e33741c231c",
      "metadata": {
        "id": "377acaae-7dd0-4d13-bc68-9e33741c231c"
      },
      "source": [
        "## New Prompt.\n",
        "We are going to improve it following the instructions of a Paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853).\n",
        "\n",
        "For each table, we will define the structure using the same syntax as in a SQL create table command, and add the sample rows of the content.\n",
        "\n",
        "Finally, at the end of the prompt, we'll include some example queries with the SQL that the model should generate. This technique is called Few-Shot Samples, in which we provide the prompt with some examples to assist it in generating the correct SQL.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5334f942",
      "metadata": {
        "id": "5334f942"
      },
      "outputs": [],
      "source": [
        "context = [ {'role':'system', 'content':\"\"\"\n",
        "    create table employees(\n",
        "        ID_Usr INT primary key,\n",
        "        name VARCHAR);\n",
        "    /*3 example rows\n",
        "    select * from employees limit 3;\n",
        "    ID_Usr    name\n",
        "    1344      George StPierre\n",
        "    2122      Jon jones\n",
        "    1265      Anderson Silva\n",
        "    */\n",
        "\n",
        "    create table salary(\n",
        "        ID_Usr INT,\n",
        "        year DATE,\n",
        "        salary FLOAT,\n",
        "        foreign key (ID_Usr) references employees(ID_Usr));\n",
        "    /*3 example rows\n",
        "    select * from salary limit 3\n",
        "    ID_Usr    date          salary\n",
        "    1344      01/01/2023    61000\n",
        "    1344      01/01/2022    60000\n",
        "    1265      01/01/2023    55000\n",
        "    */\n",
        "\n",
        "    create table studies(\n",
        "        ID_study INT,\n",
        "        ID_Usr INT,\n",
        "        educational_level INT,  /* 5=phd, 4=Master, 3=Bachelor */\n",
        "        Institution VARCHAR,\n",
        "        Years DATE,\n",
        "        Speciality VARCHAR,\n",
        "        primary key (ID_study, ID_Usr),\n",
        "        foreign key(ID_Usr) references employees (ID_Usr));\n",
        "    /*3 example rows\n",
        "    select * from studies limit 3\n",
        "    ID_Study ID_Usr educational_level Institution    Years       Speciality\n",
        "    2782     1344   3                 UC San Diego   01/01/2010  Bachelor of Science in Marketing\n",
        "    2334     1344   5                 MIT            01/01/2023  Phd. Data Science.\n",
        "    2782     2122   3                 UC San Diego   01/01/2010  Bachelor of Science in Marketing\n",
        "    */\n",
        "\"\"\"} ]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993",
      "metadata": {
        "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993"
      },
      "outputs": [],
      "source": [
        "#FEW SHOT SAMPLES\n",
        "context.append( {'role':'system', 'content':\"\"\"\n",
        " -- Maintain the SQL order simple and efficient as you can, using valid SQL Lite, answer the following questions for the table provided above.\n",
        " Question: How Many employes we have with a salary bigger than 50000?\n",
        "SELECT COUNT(*) AS total_employees\n",
        "FROM employees e\n",
        "INNER JOIN salary s ON e.ID_Usr = s.ID_Usr\n",
        "WHERE s.salary > 50000;\n",
        " Question: Return the names of the three people who have had the highest salary increase in the last three years.\n",
        "SELECT e.name\n",
        "FROM employees e\n",
        "JOIN salary s ON e.ID_usr = s.ID_usr\n",
        "WHERE s.year >= DATE_SUB(CURDATE(), INTERVAL 3 YEAR)\n",
        "GROUP BY e.name\n",
        "ORDER BY (MAX(s.salary) - MIN(s.salary)) DESC\n",
        "LIMIT 3;\n",
        "\"\"\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b90f417a",
      "metadata": {
        "id": "b90f417a"
      },
      "outputs": [],
      "source": [
        "#Functio to call the model.\n",
        "def return_CCRMSQL(user_message, context):\n",
        "\n",
        "    newcontext = context.copy()\n",
        "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=newcontext,\n",
        "            temperature=0,\n",
        "        )\n",
        "\n",
        "    return (response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c",
      "metadata": {
        "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c"
      },
      "source": [
        "## NL2SQL Samples\n",
        "We're going to review some examples generated with the old prompt and others with the new prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "59e8202c-ce34-487e-9037-c65a263423ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59e8202c-ce34-487e-9037-c65a263423ed",
        "outputId": "f7a97b9f-45d7-4f78-8979-a796c5bc42fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT e.name\n",
            "FROM employees e\n",
            "JOIN salary s ON e.ID_Usr = s.ID_Usr\n",
            "ORDER BY s.salary DESC\n",
            "LIMIT 1;\n"
          ]
        }
      ],
      "source": [
        "#new\n",
        "context_user = context.copy()\n",
        "print(return_CCRMSQL(\"The name of the employee best paid\", context_user))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
        "outputId": "029844da-5f1f-4f65-9adb-4d9c1cafacea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is your SQL:\n",
            "\n",
            "SELECT e.name\n",
            "FROM employees e\n",
            "JOIN salary s ON e.ID_usr = s.ID_usr\n",
            "ORDER BY s.salary DESC\n",
            "LIMIT 1;\n",
            "\n",
            "Explanation: This SQL query joins the \"employees\" table with the \"salary\" table using the common field \"ID_usr\". It then orders the result by the salary in descending order and selects the name of the employee with the highest salary using the LIMIT clause.\n"
          ]
        }
      ],
      "source": [
        "#old\n",
        "old_context_user = old_context.copy()\n",
        "print(return_CCRMSQL(\"The name of the employee best paid\", old_context_user))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
        "outputId": "2934cdec-bea0-44db-b047-33e70dcf8ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT s.Institution, AVG(s.salary) AS average_salary\n",
            "FROM salary s\n",
            "JOIN studies st ON s.ID_Usr = st.ID_Usr\n",
            "GROUP BY s.Institution\n",
            "ORDER BY average_salary DESC\n",
            "LIMIT 1;\n"
          ]
        }
      ],
      "source": [
        "#new\n",
        "print(return_CCRMSQL(\"Return the Institution with a higher average salary\", context_user))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
        "outputId": "605724a1-0d89-4ed9-d8ec-1aeeae6dc287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is your SQL:\n",
            "\n",
            "SELECT Institution\n",
            "FROM studies\n",
            "JOIN employees ON studies.ID_usr = employees.ID_usr\n",
            "JOIN salary ON studies.ID_usr = salary.ID_usr\n",
            "GROUP BY Institution\n",
            "ORDER BY AVG(salary) DESC\n",
            "LIMIT 1;\n",
            "\n",
            "Explanation: \n",
            "This SQL query joins the studies, employees, and salary tables using the ID_usr column. It then groups the data by Institution and calculates the average salary for each institution. The results are sorted in descending order by the average salary and the first row (highest average salary) is returned.\n"
          ]
        }
      ],
      "source": [
        "#old\n",
        "print(return_CCRMSQL(\"Return the Institution with a higher average salary\", old_context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47",
      "metadata": {
        "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "I used this structure of prompt in several projects to generate SQL from natural language, and its result is really good. For simple Databases structure like the one in the notebook the differences in the results are really small, we must understand that GPT3.5-turbo is an excellent Large Language Model and well-trained for SQL generation.\n",
        "\n",
        "As you can see in the second samples, as we increase the complexity of the question, we can find some differences in the SQL returned by the Model. It is not an easy task to decide which one is better or more efficient.\n",
        "\n",
        "If you have access to a database with real data just try to obtain some SQL orders using a prompt with this structure and test by yourself how it works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7810e219-cbeb-4350-a2a0-77fead1049bd",
      "metadata": {
        "id": "7810e219-cbeb-4350-a2a0-77fead1049bd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
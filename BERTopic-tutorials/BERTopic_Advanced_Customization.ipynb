{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXHLDxJdRzBi"
   },
   "source": [
    "# **Tutorial** - Advanced Customization in BERTopic\n",
    "(last updated 11-09-2022)\n",
    "\n",
    "In this tutorial, we will go through some advanced customization options in BERTopic. This includes hyperparameters, optimization, custom sub-models, and more!\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/MaartenGr/BERTopic/master/images/logo.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3VGFZ1USMTu"
   },
   "source": [
    "# **Data**\n",
    "For this example, we use the popular 20 Newsgroups dataset which contains roughly 18000 newsgroups posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JJij3WP6SEQD"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "docs = fetch_20newsgroups(subset='train',  remove=('headers', 'footers', 'quotes'))['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3v3bdLERcxG",
    "outputId": "3eda6b69-1005-426f-bf53-0b740b880d22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBcNmZJzSTY8"
   },
   "source": [
    "# **Hyperparameters**\n",
    "In this section, we will go through most important hyperparameters in BERTopic:\n",
    "* language\n",
    "* top_n_words\n",
    "* n_gram_range\n",
    "* min_topic_size\n",
    "* nr_topics\n",
    "* low_memory\n",
    "* calculate_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNoAyX1CSHRh"
   },
   "source": [
    "## language\n",
    "The `language` parameter is used to simplify the selection of models for those who are not familiar with sentence-transformers models.\n",
    "\n",
    "In essence, there are two options to choose from:\n",
    "* `language = \"english\"` or\n",
    "* `language = \"multilingual\"`\n",
    "\n",
    "The English model is \"distilbert-base-nli-stsb-mean-tokens\" and can be found [here](https://www.sbert.net/docs/pretrained_models.html). It is the default model that is used in BERTopic and works great for English documents.\n",
    "\n",
    "The multilingual model is \"xlm-r-bert-base-nli-stsb-mean-tokens\" and supports over 50+ languages which can be found [here](https://www.sbert.net/docs/pretrained_models.html). The model is very similar to the base model but is trained on many languages and has a slightly different architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244,
     "referenced_widgets": [
      "7d291c6740ff48a78d1149ede172c59e",
      "b236c052e9db49ac9b446aa4302722ab",
      "1de725b98fd04f1d80d603b285a3b0e4",
      "1dc1f9aff96e49e68054999cd938b39d",
      "8ebf5755d91c4b8b8774eae23f792b07",
      "aa8bb80a89ae457fa93d96abfbfaae9d",
      "cb31aa8fa6f7413281ca02081496911f",
      "a7570547d6ce4427b8f0b01527005a8d"
     ]
    },
    "id": "TfhfzqkoSJ1I",
    "outputId": "9699c9e9-22b8-425c-c89d-720ba45c99fd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0dbebbf166479abd0cb3d6b0aeaba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff6be748eeb40ca88c9b23a1cce5fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30152c57087a4edcaf348c963651edf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77725d0bc5834b9ca1a54a362aa24654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8af3e5aa0084f6fa1b6015c4f40317d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf32b6f069f474ab88eb41494d23faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c669732f9f154e1abf411ebb9f8027d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f43ccd0196548a1b654c56c64d5c93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376f4921b9684239bb7bcbc386288ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0920dfeaf89c406c80ca2a4091abeb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421ca66e60c340c0a395ff06f1aa715d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3333</td>\n",
       "      <td>-1_the_to_of_and</td>\n",
       "      <td>[the, to, of, and, you, is, it, in, that, for]</td>\n",
       "      <td>[\\nA question for you - can you give me the na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1064</td>\n",
       "      <td>0_team_game_he_season</td>\n",
       "      <td>[team, game, he, season, games, players, play,...</td>\n",
       "      <td>[#21\\tPETER AHOLA\\t\\tSeason: 2nd\\nAcquired:\\t'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>507</td>\n",
       "      <td>1_patients_msg_of_is</td>\n",
       "      <td>[patients, msg, of, is, in, medical, it, and, ...</td>\n",
       "      <td>[\\n\\nIf people are going to do this, I really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>455</td>\n",
       "      <td>2_space_launch_nasa_lunar</td>\n",
       "      <td>[space, launch, nasa, lunar, orbit, shuttle, s...</td>\n",
       "      <td>[Archive-name: space/controversy\\nLast-modifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>352</td>\n",
       "      <td>3_key_chip_clipper_encryption</td>\n",
       "      <td>[key, chip, clipper, encryption, keys, escrow,...</td>\n",
       "      <td>[Here is a revised version of my summary which...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                           Name  \\\n",
       "0     -1   3333               -1_the_to_of_and   \n",
       "1      0   1064          0_team_game_he_season   \n",
       "2      1    507           1_patients_msg_of_is   \n",
       "3      2    455      2_space_launch_nasa_lunar   \n",
       "4      3    352  3_key_chip_clipper_encryption   \n",
       "\n",
       "                                      Representation  \\\n",
       "0     [the, to, of, and, you, is, it, in, that, for]   \n",
       "1  [team, game, he, season, games, players, play,...   \n",
       "2  [patients, msg, of, is, in, medical, it, and, ...   \n",
       "3  [space, launch, nasa, lunar, orbit, shuttle, s...   \n",
       "4  [key, chip, clipper, encryption, keys, escrow,...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [\\nA question for you - can you give me the na...  \n",
       "1  [#21\\tPETER AHOLA\\t\\tSeason: 2nd\\nAcquired:\\t'...  \n",
       "2  [\\n\\nIf people are going to do this, I really ...  \n",
       "3  [Archive-name: space/controversy\\nLast-modifie...  \n",
       "4  [Here is a revised version of my summary which...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model = BERTopic(language=\"english\").fit(docs)\n",
    "topic_model.get_topic_info().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWffbXYhrUL6"
   },
   "source": [
    "## top_n_words\n",
    "`top_n_words` refers to the number of words per topic that you want extracted. In practice, I would advise you to keep this value below 30 and preferably between 10 and 20. The reasoning for this is that the more words you put in a topic the less coherent it can become. The top words are the most representative for the topic and should be focused on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xG_slPMurnmz"
   },
   "outputs": [],
   "source": [
    "topic_model = BERTopic(top_n_words=5).fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSeNGq99ruE7",
    "outputId": "94455f6a-e19c-4379-ed6a-37db82086487"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('team', 0.011046674904598354),\n",
       " ('game', 0.010057831180925245),\n",
       " ('he', 0.00925669522929331),\n",
       " ('season', 0.008136250942686008),\n",
       " ('games', 0.007948881475245443)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(topic_model.get_topic_freq().iloc[1].Topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufda3BIdruxs"
   },
   "source": [
    "## n_gram_range\n",
    "The `n_gram_range` parameter refers to the CountVectorizer used when creating the topic representation. It relates to the number of words you want in your topic representation. For example, \"New\" and \"York\" are two seperate words but are often used as \"New York\" which represents an n-gram of 2. Thus, the `n_gram_range` should be set to (1, 2) if you want \"New York\" in your topic representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "e5JwDm0HsYsA"
   },
   "outputs": [],
   "source": [
    "topic_model = BERTopic(n_gram_range=(2, 2)).fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "topcxyGFseog",
    "outputId": "3f4db4fc-bbe7-4008-bcaf-a05de376c811"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3455</td>\n",
       "      <td>-1_of the_in the_to the_on the</td>\n",
       "      <td>[of the, in the, to the, on the, it is, for th...</td>\n",
       "      <td>[[With Frank's permission, I have added some i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1072</td>\n",
       "      <td>0_in the_the game_of the_power play</td>\n",
       "      <td>[in the, the game, of the, power play, he was,...</td>\n",
       "      <td>[\\nI am trying to think how to respond to this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>521</td>\n",
       "      <td>1_it is_of the_in the_gordon banks</td>\n",
       "      <td>[it is, of the, in the, gordon banks, too soon...</td>\n",
       "      <td>[------------- cut here -----------------\\n\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>371</td>\n",
       "      <td>2_clipper chip_the clipper_the government_law ...</td>\n",
       "      <td>[clipper chip, the clipper, the government, la...</td>\n",
       "      <td>[I saw this article posted in a local newsgrou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>367</td>\n",
       "      <td>3_of the_the moon_the space_space station</td>\n",
       "      <td>[of the, the moon, the space, space station, f...</td>\n",
       "      <td>[Archive-name: space/astronaut\\nLast-modified:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name  \\\n",
       "0     -1   3455                     -1_of the_in the_to the_on the   \n",
       "1      0   1072                0_in the_the game_of the_power play   \n",
       "2      1    521                 1_it is_of the_in the_gordon banks   \n",
       "3      2    371  2_clipper chip_the clipper_the government_law ...   \n",
       "4      3    367          3_of the_the moon_the space_space station   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [of the, in the, to the, on the, it is, for th...   \n",
       "1  [in the, the game, of the, power play, he was,...   \n",
       "2  [it is, of the, in the, gordon banks, too soon...   \n",
       "3  [clipper chip, the clipper, the government, la...   \n",
       "4  [of the, the moon, the space, space station, f...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [[With Frank's permission, I have added some i...  \n",
       "1  [\\nI am trying to think how to respond to this...  \n",
       "2  [------------- cut here -----------------\\n\\n\\...  \n",
       "3  [I saw this article posted in a local newsgrou...  \n",
       "4  [Archive-name: space/astronaut\\nLast-modified:...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLrIUdCGsgkf"
   },
   "source": [
    "## min_topic_size\n",
    "`min_topic_size` is an important parameter! It is used to specify what the minimum size of a topic can be. The lower this value the more topics are created. If you set this value too high, then it is possible that simply no topics will be created!\n",
    "\n",
    "It is advised to play around with this value depending on the size of the your dataset. If it nears a million documents, then it advised to set it much higher than the default of 10, for example 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NprlPzEls3kX"
   },
   "outputs": [],
   "source": [
    "topic_model = BERTopic(min_topic_size=20).fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "ngLuRWyus4nr",
    "outputId": "11895fd7-ea9b-4773-ee72-0147556b94da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>2848</td>\n",
       "      <td>-1_the_to_and_of</td>\n",
       "      <td>[the, to, and, of, is, for, in, it, you, that]</td>\n",
       "      <td>[\\n\\nBut you haven't taken into the account of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1063</td>\n",
       "      <td>0_he_team_the_game</td>\n",
       "      <td>[he, team, the, game, in, was, season, games, ...</td>\n",
       "      <td>[\\nI am trying to think how to respond to this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>1_car_the_it_to</td>\n",
       "      <td>[car, the, it, to, and, my, bike, you, on, in]</td>\n",
       "      <td>[   I need some advice on having someone ride ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>734</td>\n",
       "      <td>2_god_of_that_is</td>\n",
       "      <td>[god, of, that, is, the, not, to, and, in, jesus]</td>\n",
       "      <td>[I posted this several days ago for Dave Butle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>511</td>\n",
       "      <td>3_of_is_it_to</td>\n",
       "      <td>[of, is, it, to, in, and, the, that, my, patie...</td>\n",
       "      <td>[\\nGee!  Maybe I've misjudged you, Russell.  A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                Name  \\\n",
       "0     -1   2848    -1_the_to_and_of   \n",
       "1      0   1063  0_he_team_the_game   \n",
       "2      1   1061     1_car_the_it_to   \n",
       "3      2    734    2_god_of_that_is   \n",
       "4      3    511       3_of_is_it_to   \n",
       "\n",
       "                                      Representation  \\\n",
       "0     [the, to, and, of, is, for, in, it, you, that]   \n",
       "1  [he, team, the, game, in, was, season, games, ...   \n",
       "2     [car, the, it, to, and, my, bike, you, on, in]   \n",
       "3  [god, of, that, is, the, not, to, and, in, jesus]   \n",
       "4  [of, is, it, to, in, and, the, that, my, patie...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [\\n\\nBut you haven't taken into the account of...  \n",
       "1  [\\nI am trying to think how to respond to this...  \n",
       "2  [   I need some advice on having someone ride ...  \n",
       "3  [I posted this several days ago for Dave Butle...  \n",
       "4  [\\nGee!  Maybe I've misjudged you, Russell.  A...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-9goJnis8fq"
   },
   "source": [
    "## nr_topics\n",
    "`nr_topics` can be a tricky parameter. It specifies, after training the topic model, the number of topics that will be reduced to. For example, if your topic model results in 100 topics but you have set `nr_topics` to 20 then the topic model will try to reduce the number of topics from 100 to 20.\n",
    "\n",
    "This reduction can take awhile as each reduction in topics activates a c-TF-IDF calculation. If this is set to None, no reduction is applied. Use \"auto\" to automatically reduce topics that using HDBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Qgf0jxrptisu"
   },
   "outputs": [],
   "source": [
    "topic_model = BERTopic(nr_topics=10).fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "seJff7Wltlz8",
    "outputId": "46bb4597-deb3-41ca-abc9-2fd05b23f021"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3471</td>\n",
       "      <td>-1_the_to_of_and</td>\n",
       "      <td>[the, to, of, and, is, in, that, it, for, you]</td>\n",
       "      <td>[\\n       Mr. Parsli, I have to take exception...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2178</td>\n",
       "      <td>0_the_to_and_is</td>\n",
       "      <td>[the, to, and, is, of, for, in, it, that, this]</td>\n",
       "      <td>[-------------------------------------\\n\\t+ .....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1972</td>\n",
       "      <td>1_the_of_to_and</td>\n",
       "      <td>[the, of, to, and, that, in, is, it, you, not]</td>\n",
       "      <td>[Accounts of Anti-Armenian Human Right Violati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1375</td>\n",
       "      <td>2_the_in_to_and</td>\n",
       "      <td>[the, in, to, and, he, of, that, was, team, is]</td>\n",
       "      <td>[As the Sharks' season came to a close tonight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1240</td>\n",
       "      <td>3_the_and_to_of</td>\n",
       "      <td>[the, and, to, of, for, in, is, space, it, on]</td>\n",
       "      <td>[Two developments have brought these type of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>512</td>\n",
       "      <td>4_the_of_to_and</td>\n",
       "      <td>[the, of, to, and, is, in, it, that, for, are]</td>\n",
       "      <td>[------------- cut here -----------------\\nlim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>241</td>\n",
       "      <td>5_the_to_is_of</td>\n",
       "      <td>[the, to, is, of, in, and, it, you, for, that]</td>\n",
       "      <td>[\\n   &gt;Anyway, over the weekend, I was resting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>230</td>\n",
       "      <td>6_the_to_you_and</td>\n",
       "      <td>[the, to, you, and, it, of, that, my, is, in]</td>\n",
       "      <td>[\\n\\n\\nIMHO = in my humble opinion!!\\n\\n\\n\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>81</td>\n",
       "      <td>7_maxaxaxaxaxaxaxaxaxaxaxaxaxaxax_the_of_den</td>\n",
       "      <td>[maxaxaxaxaxaxaxaxaxaxaxaxaxaxax, the, of, den...</td>\n",
       "      <td>[\\nSorry!! :-)\\n\\nCall the four points A, B, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>8_ground_the_grounding_neutral</td>\n",
       "      <td>[ground, the, grounding, neutral, conductor, w...</td>\n",
       "      <td>[\\nNot according to the NEC nor the CEC, as ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                          Name  \\\n",
       "0     -1   3471                              -1_the_to_of_and   \n",
       "1      0   2178                               0_the_to_and_is   \n",
       "2      1   1972                               1_the_of_to_and   \n",
       "3      2   1375                               2_the_in_to_and   \n",
       "4      3   1240                               3_the_and_to_of   \n",
       "5      4    512                               4_the_of_to_and   \n",
       "6      5    241                                5_the_to_is_of   \n",
       "7      6    230                              6_the_to_you_and   \n",
       "8      7     81  7_maxaxaxaxaxaxaxaxaxaxaxaxaxaxax_the_of_den   \n",
       "9      8     14                8_ground_the_grounding_neutral   \n",
       "\n",
       "                                      Representation  \\\n",
       "0     [the, to, of, and, is, in, that, it, for, you]   \n",
       "1    [the, to, and, is, of, for, in, it, that, this]   \n",
       "2     [the, of, to, and, that, in, is, it, you, not]   \n",
       "3    [the, in, to, and, he, of, that, was, team, is]   \n",
       "4     [the, and, to, of, for, in, is, space, it, on]   \n",
       "5     [the, of, to, and, is, in, it, that, for, are]   \n",
       "6     [the, to, is, of, in, and, it, you, for, that]   \n",
       "7      [the, to, you, and, it, of, that, my, is, in]   \n",
       "8  [maxaxaxaxaxaxaxaxaxaxaxaxaxaxax, the, of, den...   \n",
       "9  [ground, the, grounding, neutral, conductor, w...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [\\n       Mr. Parsli, I have to take exception...  \n",
       "1  [-------------------------------------\\n\\t+ .....  \n",
       "2  [Accounts of Anti-Armenian Human Right Violati...  \n",
       "3  [As the Sharks' season came to a close tonight...  \n",
       "4  [Two developments have brought these type of a...  \n",
       "5  [------------- cut here -----------------\\nlim...  \n",
       "6  [\\n   >Anyway, over the weekend, I was resting...  \n",
       "7  [\\n\\n\\nIMHO = in my humble opinion!!\\n\\n\\n\\n\\n...  \n",
       "8  [\\nSorry!! :-)\\n\\nCall the four points A, B, C...  \n",
       "9  [\\nNot according to the NEC nor the CEC, as ex...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wv9TpCYQuEQg"
   },
   "source": [
    "Note that I have set the number of topics quite low for educational purposes. In practice, do not set this value to low as it forces topics to merge that should not be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qOOqwCp_uRHk"
   },
   "outputs": [],
   "source": [
    "topic_model = BERTopic(nr_topics=\"auto\").fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "hbCZtV4duTxB",
    "outputId": "5ad11dfa-df61-4298-c25a-91e493400d90"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3766</td>\n",
       "      <td>-1_the_to_of_and</td>\n",
       "      <td>[the, to, of, and, is, in, for, that, it, you]</td>\n",
       "      <td>[[This is a co-authored report from two of us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1604</td>\n",
       "      <td>0_for_the_and_with</td>\n",
       "      <td>[for, the, and, with, to, it, is, have, on, card]</td>\n",
       "      <td>[\\n\\n*nnnnnnnng* Thank you for playing, I cann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1078</td>\n",
       "      <td>1_team_he_game_the</td>\n",
       "      <td>[team, he, game, the, in, season, games, was, ...</td>\n",
       "      <td>[\\n\\tOh, yeah.  Dave Winfield--marginal player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>549</td>\n",
       "      <td>2_key_the_to_is</td>\n",
       "      <td>[key, the, to, is, of, be, and, encryption, fo...</td>\n",
       "      <td>[We have received a number of requests for a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>3_window_image_jpeg_is</td>\n",
       "      <td>[window, image, jpeg, is, windows, file, to, a...</td>\n",
       "      <td>[Archive-name: graphics/resources-list/part2\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                    Name  \\\n",
       "0     -1   3766        -1_the_to_of_and   \n",
       "1      0   1604      0_for_the_and_with   \n",
       "2      1   1078      1_team_he_game_the   \n",
       "3      2    549         2_key_the_to_is   \n",
       "4      3    500  3_window_image_jpeg_is   \n",
       "\n",
       "                                      Representation  \\\n",
       "0     [the, to, of, and, is, in, for, that, it, you]   \n",
       "1  [for, the, and, with, to, it, is, have, on, card]   \n",
       "2  [team, he, game, the, in, season, games, was, ...   \n",
       "3  [key, the, to, is, of, be, and, encryption, fo...   \n",
       "4  [window, image, jpeg, is, windows, file, to, a...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [[This is a co-authored report from two of us ...  \n",
       "1  [\\n\\n*nnnnnnnng* Thank you for playing, I cann...  \n",
       "2  [\\n\\tOh, yeah.  Dave Winfield--marginal player...  \n",
       "3  [We have received a number of requests for a r...  \n",
       "4  [Archive-name: graphics/resources-list/part2\\n...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kU-FDXi_tm6o"
   },
   "source": [
    "## low_memory + calculate_probabilities\n",
    "`low_memory` sets UMAP's `low_memory` to True to make sure that less memory is used in computation. This slows down computation but allows UMAP to be ran on low memory machines.\n",
    "\n",
    "`calculate_probabilities` lets you calculate the probabilities of each topic to each document. This is computationally quite expensive and is turned off by default.\n",
    "\n",
    "Thus, to run BERTopic on machines that are a bit less powerful, use the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PlFXDRu9ucjW"
   },
   "outputs": [],
   "source": [
    "topic_model = BERTopic(low_memory=True, calculate_probabilities=False).fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "KOAng6nPu3iv",
    "outputId": "0ad595ef-b737-44dd-f63d-f1bee164f7c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3504</td>\n",
       "      <td>-1_to_the_of_you</td>\n",
       "      <td>[to, the, of, you, and, is, it, that, in, for]</td>\n",
       "      <td>[[why are atheists atheists/ believes it could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1070</td>\n",
       "      <td>0_team_game_he_season</td>\n",
       "      <td>[team, game, he, season, games, players, play,...</td>\n",
       "      <td>[Philadelphia at Chicago:  Teams tied for 1st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>505</td>\n",
       "      <td>1_patients_msg_of_is</td>\n",
       "      <td>[patients, msg, of, is, in, it, medical, and, ...</td>\n",
       "      <td>[------------- cut here -----------------\\n\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>385</td>\n",
       "      <td>2_space_launch_nasa_lunar</td>\n",
       "      <td>[space, launch, nasa, lunar, orbit, satellite,...</td>\n",
       "      <td>[Archive-name: space/new_probes\\nLast-modified...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>343</td>\n",
       "      <td>3_key_chip_clipper_encryption</td>\n",
       "      <td>[key, chip, clipper, encryption, keys, escrow,...</td>\n",
       "      <td>[Hmm, followup on my own posting... Well, who ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                           Name  \\\n",
       "0     -1   3504               -1_to_the_of_you   \n",
       "1      0   1070          0_team_game_he_season   \n",
       "2      1    505           1_patients_msg_of_is   \n",
       "3      2    385      2_space_launch_nasa_lunar   \n",
       "4      3    343  3_key_chip_clipper_encryption   \n",
       "\n",
       "                                      Representation  \\\n",
       "0     [to, the, of, you, and, is, it, that, in, for]   \n",
       "1  [team, game, he, season, games, players, play,...   \n",
       "2  [patients, msg, of, is, in, it, medical, and, ...   \n",
       "3  [space, launch, nasa, lunar, orbit, satellite,...   \n",
       "4  [key, chip, clipper, encryption, keys, escrow,...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [[why are atheists atheists/ believes it could...  \n",
       "1  [Philadelphia at Chicago:  Teams tied for 1st ...  \n",
       "2  [------------- cut here -----------------\\n\\n\\...  \n",
       "3  [Archive-name: space/new_probes\\nLast-modified...  \n",
       "4  [Hmm, followup on my own posting... Well, who ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCBkN39qCrPt"
   },
   "source": [
    "# **Custom sub-models**\n",
    "There are three models underpinning BERTopic that are most important in creating the topics, namely UMAP, HDBSCAN, and CountVectorizer. The parameters of these models have been carefully selected to give the best results. However, there is no one-size-fits-all solution using these default parameters.\n",
    "\n",
    "Therefore, BERTopic allows you to pass in any custom UMAP, HDBSCAN, and/or CountVectorizer with the parameters that best suit your use-case. For example, you might want to change the minimum document frequency in CountVectorizer or use a different distance metric in HDBSCAN or UMAP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lH0X95gjmhY"
   },
   "source": [
    "## **Dimensionality Reduction**\n",
    "\n",
    "One important aspect of BERTopic is dimensionality reduction of the embeddings. Typically, embeddings are at least 384 in length and many clustering algorithms have difficulty clustering in such a high dimensional space. A solution is to reduce the dimensionality of the embeddings to a workable dimensional space (e.g., 5) for clustering algorithms to work with.\n",
    "\n",
    "In BERTopic, we typically use UMAP as it is able to capture both the local and global high-dimensional space in lower dimensions. However, there are other solutions out there, such as PCA that users might be interested in trying out.\n",
    "\n",
    "We have seen that developments in the artificial intelligence fields are quite fast and that whatever mights be state-of-the-art now, could be different a year or even months later. Therefore, BERTopic allows you to use any dimensionality reduction algorithm that you would like to be using.\n",
    "\n",
    "As a result, the `umap_model` parameter in BERTopic now allows for a variety of dimensionality reduction models. To do so, the class should have the following attributes:\n",
    "\n",
    "* .fit(X)\n",
    "  * A function that can be used to fit the model\n",
    "* .transform(X)\n",
    "  * A transform function that transforms the input to a lower dimensional size\n",
    "\n",
    "In other words, it should have the following structure:\n",
    "\n",
    "```python\n",
    "class DimensionalityReduction:\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsRpzDTju7V6"
   },
   "source": [
    "### UMAP\n",
    "UMAP is an amazing technique for dimensionality reduction. In BERTopic, it is used to reduce the dimensionality of document embedding into something that is easier to use with HDBSCAN in order to create good clusters.\n",
    "\n",
    "However, it does has a significant number of parameters you could take into account. As exposing all parameters in BERTopic would be difficult to manage, we can instantiate our UMAP model and pass it to BERTopic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "kubUJLouvHSg"
   },
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "umap_model = UMAP(n_neighbors=15, n_components=10, min_dist=0.0, metric='cosine')\n",
    "topic_model = BERTopic(umap_model=umap_model).fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "4mnq5xWzviey",
    "outputId": "63946d50-3a3b-4a69-87f6-1986fd053ff9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3383</td>\n",
       "      <td>-1_the_to_of_and</td>\n",
       "      <td>[the, to, of, and, is, in, you, it, for, that]</td>\n",
       "      <td>[\\n[ stuff deleted ]\\n   |&gt; Are you calling na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1072</td>\n",
       "      <td>0_team_game_he_season</td>\n",
       "      <td>[team, game, he, season, games, players, play,...</td>\n",
       "      <td>[Individual leaders by total points (Final sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>508</td>\n",
       "      <td>1_patients_msg_of_is</td>\n",
       "      <td>[patients, msg, of, is, medical, in, it, and, ...</td>\n",
       "      <td>[Hi,\\n\\nI've just returned from a visit with m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>479</td>\n",
       "      <td>2_space_launch_nasa_lunar</td>\n",
       "      <td>[space, launch, nasa, lunar, orbit, the, satel...</td>\n",
       "      <td>[Archive-name: space/probe\\nLast-modified: $Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>344</td>\n",
       "      <td>3_key_chip_clipper_encryption</td>\n",
       "      <td>[key, chip, clipper, encryption, keys, escrow,...</td>\n",
       "      <td>[The following document summarizes the Clipper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                           Name  \\\n",
       "0     -1   3383               -1_the_to_of_and   \n",
       "1      0   1072          0_team_game_he_season   \n",
       "2      1    508           1_patients_msg_of_is   \n",
       "3      2    479      2_space_launch_nasa_lunar   \n",
       "4      3    344  3_key_chip_clipper_encryption   \n",
       "\n",
       "                                      Representation  \\\n",
       "0     [the, to, of, and, is, in, you, it, for, that]   \n",
       "1  [team, game, he, season, games, players, play,...   \n",
       "2  [patients, msg, of, is, medical, in, it, and, ...   \n",
       "3  [space, launch, nasa, lunar, orbit, the, satel...   \n",
       "4  [key, chip, clipper, encryption, keys, escrow,...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [\\n[ stuff deleted ]\\n   |> Are you calling na...  \n",
       "1  [Individual leaders by total points (Final sta...  \n",
       "2  [Hi,\\n\\nI've just returned from a visit with m...  \n",
       "3  [Archive-name: space/probe\\nLast-modified: $Da...  \n",
       "4  [The following document summarizes the Clipper...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PS2ozQJ8jvyw"
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQMWSgOzjxld"
   },
   "source": [
    "Although UMAP works quite well in BERTopic and is typically advised, you might want to be using PCA instead. It can be faster to train and to perform inference with. To use PCA, we can simply import it from sklearn and pass it to the `umap_model` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pGSwzo0Gjw6R"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "dim_model = PCA(n_components=5)\n",
    "topic_model = BERTopic(umap_model=dim_model).fit(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0ANC_akj4IQ"
   },
   "source": [
    "## **Clustering**\n",
    "\n",
    "After reducing the dimensionality of our input embeddings, we need to cluster them into groups of similar embeddings in order to extract our topics. This process of clustering is quite important because the more performant our clustering technique the more accurate our topic representations are.\n",
    "\n",
    "In BERTopic, we typically use HDBSCAN as it is quite capable of capturing structures with different densities. However, there is not perfect clustering model and you might want to be using something entirely different for you use case. Moreover, what if a new state-of-the-art model is released tomorrow? We would like to able to use that in BERTopic, right?\n",
    "\n",
    "As a result, the `hdbscan_model` parameter in BERTopic now allows for a variety of clustering models. To do so, the class should have the following attributes:\n",
    "\n",
    "* .fit(X)\n",
    "  * A function that can be used to fit the model\n",
    "* .predict(X)\n",
    "  * A predict function that transforms the input to cluster labels\n",
    "* .labels_\n",
    "  * The labels after fitting the model\n",
    "\n",
    "In other words, it should have the following structure:\n",
    "\n",
    "```python\n",
    "class ClusterModel:\n",
    "    def fit(self, X):\n",
    "        self.labels_ = None\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQt4rU4Qu814"
   },
   "source": [
    "### HDBSCAN\n",
    "After reducing the embeddings with UMAP, we use HDBSCAN to cluster our documents into clusters of similar documents. Similar to UMAP, HDBSCAN has many parameters that could be tweaked in order to improve the cluster's quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "m2S6jHpfvH0l"
   },
   "outputs": [],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=10, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "topic_model = BERTopic(hdbscan_model=hdbscan_model).fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "jQHJ3AU9vjY9",
    "outputId": "905e014f-0a0c-481c-e6ae-1e411afe36e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3405</td>\n",
       "      <td>-1_the_to_of_is</td>\n",
       "      <td>[the, to, of, is, and, that, you, it, in, for]</td>\n",
       "      <td>[\\n\\nBut you haven't taken into the account of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1078</td>\n",
       "      <td>0_team_game_he_season</td>\n",
       "      <td>[team, game, he, season, games, players, play,...</td>\n",
       "      <td>[\\n\\n\"Deeply rooted rivalry?\" Ahem, Jokerit ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>513</td>\n",
       "      <td>1_patients_msg_of_is</td>\n",
       "      <td>[patients, msg, of, is, medical, in, it, disea...</td>\n",
       "      <td>[\\n   The following is from a critique of a \"6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>404</td>\n",
       "      <td>2_space_launch_nasa_lunar</td>\n",
       "      <td>[space, launch, nasa, lunar, orbit, satellite,...</td>\n",
       "      <td>[Archive-name: space/acronyms\\nEdition: 8\\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>399</td>\n",
       "      <td>3_car_bike_cars_engine</td>\n",
       "      <td>[car, bike, cars, engine, miles, tires, for, i...</td>\n",
       "      <td>[\\nWhile I don't read normally read this group...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                       Name  \\\n",
       "0     -1   3405            -1_the_to_of_is   \n",
       "1      0   1078      0_team_game_he_season   \n",
       "2      1    513       1_patients_msg_of_is   \n",
       "3      2    404  2_space_launch_nasa_lunar   \n",
       "4      3    399     3_car_bike_cars_engine   \n",
       "\n",
       "                                      Representation  \\\n",
       "0     [the, to, of, is, and, that, you, it, in, for]   \n",
       "1  [team, game, he, season, games, players, play,...   \n",
       "2  [patients, msg, of, is, medical, in, it, disea...   \n",
       "3  [space, launch, nasa, lunar, orbit, satellite,...   \n",
       "4  [car, bike, cars, engine, miles, tires, for, i...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [\\n\\nBut you haven't taken into the account of...  \n",
       "1  [\\n\\n\"Deeply rooted rivalry?\" Ahem, Jokerit ha...  \n",
       "2  [\\n   The following is from a critique of a \"6...  \n",
       "3  [Archive-name: space/acronyms\\nEdition: 8\\n\\nA...  \n",
       "4  [\\nWhile I don't read normally read this group...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZ_qBaMSkdxp"
   },
   "source": [
    "### k-Means\n",
    "\n",
    "Although HDBSCAN works quite well in BERTopic and is typically advised, you might want to be using k-Means instead. It allows you to select how many clusters you would like and forces every single point to be in a cluster. Therefore, no outliers will be created. This has also has disadvantages. When you force every single point in a cluster, it will mean that the cluster is highly likely to contain noise which can hurt the topic representations. As a small tip, using the `vectorizer_model=CountVectorizer(stop_words=\"english\")` helps quite a bit to then improve the topic representation.\n",
    "\n",
    "Having said that, using k-Means is quite straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "LiOWZdlukjpy"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "cluster_model = KMeans(n_clusters=50)\n",
    "topic_model = BERTopic(hdbscan_model=cluster_model).fit(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtqYnWP0u5uN"
   },
   "source": [
    "## CountVectorizer\n",
    "Lastly, in order to create our topic representation we use the CountVectorizer to extract all possible words. Perhaps you want to remove specific stop words or used a different tokenizer. Simply instantiate your CountVectorizer and pass it to BERTopic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "N7ip72cxtstL"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 2), stop_words=\"english\")\n",
    "topic_model = BERTopic(vectorizer_model=vectorizer_model).fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "WZTBPfqOvj-7",
    "outputId": "f6711673-d1d2-4c75-d711-35db4d7cd12e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3560</td>\n",
       "      <td>-1_dont know_hard disk_anonymous ftp_im sure</td>\n",
       "      <td>[dont know, hard disk, anonymous ftp, im sure,...</td>\n",
       "      <td>[Archive-name: typing-injury-faq/general\\nVers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1071</td>\n",
       "      <td>0_power play_st louis_scorer pts_pts pt</td>\n",
       "      <td>[power play, st louis, scorer pts, pts pt, new...</td>\n",
       "      <td>[1992-93 Los Angeles Kings Schedule/Results\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>504</td>\n",
       "      <td>1_gordon banks_intellect gebcadredslpittedu_ge...</td>\n",
       "      <td>[gordon banks, intellect gebcadredslpittedu, g...</td>\n",
       "      <td>[\\n\\nSo just what was it you wanted to say?\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>368</td>\n",
       "      <td>2_clipper chip_law enforcement_serial number_s...</td>\n",
       "      <td>[clipper chip, law enforcement, serial number,...</td>\n",
       "      <td>[SECRET PURPOSE OF FALKLANDS WAR;  [with IN-VI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>310</td>\n",
       "      <td>3_hello hi_huh hello_hi ites_hi ditto</td>\n",
       "      <td>[hello hi, huh hello, hi ites, hi ditto, ditto...</td>\n",
       "      <td>[\\n, \\n\\n\\n\\n\\n      \\n, \\n\\n\\n\\n\\n]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name  \\\n",
       "0     -1   3560       -1_dont know_hard disk_anonymous ftp_im sure   \n",
       "1      0   1071            0_power play_st louis_scorer pts_pts pt   \n",
       "2      1    504  1_gordon banks_intellect gebcadredslpittedu_ge...   \n",
       "3      2    368  2_clipper chip_law enforcement_serial number_s...   \n",
       "4      3    310              3_hello hi_huh hello_hi ites_hi ditto   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [dont know, hard disk, anonymous ftp, im sure,...   \n",
       "1  [power play, st louis, scorer pts, pts pt, new...   \n",
       "2  [gordon banks, intellect gebcadredslpittedu, g...   \n",
       "3  [clipper chip, law enforcement, serial number,...   \n",
       "4  [hello hi, huh hello, hi ites, hi ditto, ditto...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [Archive-name: typing-injury-faq/general\\nVers...  \n",
       "1  [1992-93 Los Angeles Kings Schedule/Results\\n\\...  \n",
       "2  [\\n\\nSo just what was it you wanted to say?\\n\\...  \n",
       "3  [SECRET PURPOSE OF FALKLANDS WAR;  [with IN-VI...  \n",
       "4               [\\n, \\n\\n\\n\\n\\n      \\n, \\n\\n\\n\\n\\n]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUPxgAKxkqTm"
   },
   "source": [
    "## c-TF-IDF\n",
    "\n",
    "In BERTopic, in order to get an accurate representation of the topics from our bag-of-words matrix, TF-IDF was adjusted to work on a cluster/categorical/topic-level instead of a document-level. This adjusted TF-IDF representation is called c-TF-IDF takes into account what makes the documents in once cluster different from documents in another cluster:\n",
    "\n",
    "\n",
    "![ctfidf.PNG](data:image/png;base64,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)\n",
    "\n",
    "\n",
    "Each cluster is converted to a single document instead of a set of documents. Then, we extract the frequency of word `x` in class `c`, where `c` refers to the cluster we created before. This results in our class-based `tf` representation. This representation is L1-normalized to account for the differences in topic sizes.\n",
    "\n",
    "Then, we take take the logarithm of one plus the average number of words per class A divided by the frequency of word `x` across all classes. We add plus one within the logarithm to force values to be positive. This results in our class-based idf representation. Like with the classic TF-IDF, we then multiply `tf` with `idf` to get the importance score per word in each class. In other words, the classical TF-IDF procedure is not used here but a modified version of the algorithm that allows for a much better representation.\n",
    "\n",
    "This class-based TF-IDF representation is enabled by default in BERTopic. However, we can explicitly pass it to BERTopic through the ctfidf_model allowing for parameter tuning and the customization of the topic extraction technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1NVY1fF0krI8"
   },
   "outputs": [],
   "source": [
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "topic_model = BERTopic(ctfidf_model=ctfidf_model).fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (llm)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1dc1f9aff96e49e68054999cd938b39d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7570547d6ce4427b8f0b01527005a8d",
      "placeholder": "​",
      "style": "IPY_MODEL_cb31aa8fa6f7413281ca02081496911f",
      "value": " 245M/245M [00:13&lt;00:00, 18.7MB/s]"
     }
    },
    "1de725b98fd04f1d80d603b285a3b0e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa8bb80a89ae457fa93d96abfbfaae9d",
      "max": 244715968,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8ebf5755d91c4b8b8774eae23f792b07",
      "value": 244715968
     }
    },
    "7d291c6740ff48a78d1149ede172c59e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1de725b98fd04f1d80d603b285a3b0e4",
       "IPY_MODEL_1dc1f9aff96e49e68054999cd938b39d"
      ],
      "layout": "IPY_MODEL_b236c052e9db49ac9b446aa4302722ab"
     }
    },
    "8ebf5755d91c4b8b8774eae23f792b07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a7570547d6ce4427b8f0b01527005a8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa8bb80a89ae457fa93d96abfbfaae9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b236c052e9db49ac9b446aa4302722ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb31aa8fa6f7413281ca02081496911f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "130PIKarkY1_"
   },
   "source": [
    "# ~~Enabling the GPU~~\n",
    "\n",
    "~~First, you'll need to enable GPUs for the notebook:~~\n",
    "\n",
    "~~- Navigate to Editâ†’Notebook Settings~~\n",
    "~~- select GPU from the Hardware Accelerator drop-down~~\n",
    "\n",
    "~~[Reference](https://colab.research.google.com/notebooks/gpu.ipynb)~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXHLDxJdRzBi"
   },
   "source": [
    "# **Tutorial** - Topic Modeling with BERTopic\n",
    "(last updated 01-09-2022)\n",
    "\n",
    "In this tutorial we will be exploring how to use BERTopic to create topics from the well-known 20Newsgroups dataset. The most frequent use-cases and methods are discussed together with important parameters to keep a look out for.\n",
    "\n",
    "\n",
    "## BERTopic\n",
    "BERTopic is a topic modeling technique that leverages ðŸ¤— transformers and a custom class-based TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/MaartenGr/BERTopic/master/images/logo.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lj2MUI9Mkdxu"
   },
   "source": [
    "# ~~**Installing BERTopic**~~\n",
    "\n",
    "~~We start by installing BERTopic from PyPi:~~\n",
    "\n",
    "```\n",
    "%%capture\n",
    "!pip install bertopic\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ehO3emgk96g"
   },
   "source": [
    "## ~~Restart the Notebook~~\n",
    "~~After installing BERTopic, some packages that were already loaded were updated and in order to correctly use them, we should now restart the notebook.~~\n",
    "\n",
    "~~From the Menu:~~\n",
    "\n",
    "~~Runtime â†’ Restart Runtime~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3VGFZ1USMTu"
   },
   "source": [
    "# Data\n",
    "For this example, we use the popular 20 Newsgroups dataset which contains roughly 18000 newsgroups posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JJij3WP6SEQD"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBcNmZJzSTY8"
   },
   "source": [
    "# **Topic Modeling**\n",
    "\n",
    "In this example, we will go through the main components of BERTopic and the steps necessary to create a strong topic model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QI6vwelqnTL-"
   },
   "source": [
    "## Training\n",
    "\n",
    "We start by instantiating BERTopic. We set language to `english` since our documents are in the English language. If you would like to use a multi-lingual model, please use `language=\"multilingual\"` instead.\n",
    "\n",
    "We will also calculate the topic probabilities. However, this can slow down BERTopic significantly at large amounts of data (>100_000 documents). It is advised to turn this off if you want to speed up the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TfhfzqkoSJ1I"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 10:07:34,254 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac680aec8619469da45d3e071ea451b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 10:08:08,573 - BERTopic - Embedding - Completed âœ“\n",
      "2024-03-01 10:08:08,574 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-03-01 10:08:43,089 - BERTopic - Dimensionality - Completed âœ“\n",
      "2024-03-01 10:08:43,091 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-03-01 10:09:05,419 - BERTopic - Cluster - Completed âœ“\n",
      "2024-03-01 10:09:05,519 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-03-01 10:09:08,571 - BERTopic - Representation - Completed âœ“\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJs94tXDo4f6"
   },
   "source": [
    "**NOTE**: Use `language=\"multilingual\"` to select a model that support 50+ languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5O3KpHTnVpz"
   },
   "source": [
    "## Extracting Topics\n",
    "After fitting our model, we can start by looking at the results. Typically, we look at the most frequent topics first as they best represent the collection of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "ScBUgXn06IK6",
    "outputId": "ee49a346-8d12-41c4-c7e9-8c1b6782c636"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>6659</td>\n",
       "      <td>-1_to_the_is_of</td>\n",
       "      <td>[to, the, is, of, and, in, for, it, you, that]</td>\n",
       "      <td>[\\n/(hudson)\\n/If someone inflicts pain on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1822</td>\n",
       "      <td>0_game_team_games_he</td>\n",
       "      <td>[game, team, games, he, players, season, hocke...</td>\n",
       "      <td>[By Dave Luecking Of The Post-Dispatch Staff\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>1_key_clipper_chip_encryption</td>\n",
       "      <td>[key, clipper, chip, encryption, keys, escrow,...</td>\n",
       "      <td>[The following document summarizes the Clipper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>530</td>\n",
       "      <td>2_ites_hello_cheek_hi</td>\n",
       "      <td>[ites, hello, cheek, hi, yep, huh, ken, why, e...</td>\n",
       "      <td>[\\n \\n                                        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>464</td>\n",
       "      <td>3_israel_israeli_jews_arab</td>\n",
       "      <td>[israel, israeli, jews, arab, jewish, arabs, p...</td>\n",
       "      <td>[From: Center for Policy Research &lt;cpr&gt;\\nSubje...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                           Name  \\\n",
       "0     -1   6659                -1_to_the_is_of   \n",
       "1      0   1822           0_game_team_games_he   \n",
       "2      1    580  1_key_clipper_chip_encryption   \n",
       "3      2    530          2_ites_hello_cheek_hi   \n",
       "4      3    464     3_israel_israeli_jews_arab   \n",
       "\n",
       "                                      Representation  \\\n",
       "0     [to, the, is, of, and, in, for, it, you, that]   \n",
       "1  [game, team, games, he, players, season, hocke...   \n",
       "2  [key, clipper, chip, encryption, keys, escrow,...   \n",
       "3  [ites, hello, cheek, hi, yep, huh, ken, why, e...   \n",
       "4  [israel, israeli, jews, arab, jewish, arabs, p...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [\\n/(hudson)\\n/If someone inflicts pain on the...  \n",
       "1  [By Dave Luecking Of The Post-Dispatch Staff\\n...  \n",
       "2  [The following document summarizes the Clipper...  \n",
       "3  [\\n \\n                                        ...  \n",
       "4  [From: Center for Policy Research <cpr>\\nSubje...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = topic_model.get_topic_info(); freq.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BtOgifV7Q-H"
   },
   "source": [
    "-1 refers to all outliers and should typically be ignored. Next, let's take a look at a frequent topic that were generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVpvT4bA6KiN",
    "outputId": "9cf99b89-30bb-45fe-b98b-063f8f3624d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('game', 0.010262228621159025),\n",
       " ('team', 0.008955986773667332),\n",
       " ('games', 0.007138858787269039),\n",
       " ('he', 0.0069181842312463085),\n",
       " ('players', 0.006281264089160354),\n",
       " ('season', 0.0062005065961159185),\n",
       " ('hockey', 0.0060906558950869875),\n",
       " ('play', 0.0057324961478944355),\n",
       " ('25', 0.005591470582921641),\n",
       " ('year', 0.0055647305550234885)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(0)  # Select the most frequent topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixc-X2JzodrZ"
   },
   "source": [
    "**NOTE**: BERTopic is stocastich which mmeans that the topics might differ across runs. This is mostly due to the stocastisch nature of UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FX_Ngb3PpRFG"
   },
   "outputs": [],
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j91cP3xBpWDM"
   },
   "source": [
    "## Attributes\n",
    "\n",
    "There are a number of attributes that you can access after having trained your BERTopic model:\n",
    "\n",
    "\n",
    "| Attribute | Description |\n",
    "|------------------------|---------------------------------------------------------------------------------------------|\n",
    "| topics_               | The topics that are generated for each document after training or updating the topic model. |\n",
    "| probabilities_ | The probabilities that are generated for each document if HDBSCAN is used. |\n",
    "| topic_sizes_           | The size of each topic                                                                      |\n",
    "| topic_mapper_          | A class for tracking topics and their mappings anytime they are merged/reduced.             |\n",
    "| topic_representations_ | The top *n* terms per topic and their respective c-TF-IDF values.                             |\n",
    "| c_tf_idf_              | The topic-term matrix as calculated through c-TF-IDF.                                       |\n",
    "| topic_labels_          | The default labels for each topic.                                                          |\n",
    "| custom_labels_         | Custom labels for each topic as generated through `.set_topic_labels`.                                                               |\n",
    "| topic_embeddings_      | The embeddings for each topic if `embedding_model` was used.                                                              |\n",
    "| representative_docs_   | The representative documents for each topic if HDBSCAN is used.                                                |\n",
    "\n",
    "For example, to access the predicted topics for the first 10 documents, we simply run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uCMHaWVMpbo3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, -1, -1, 40, 102, 209, -1, 0, 0, -1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.topics_[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbT2Bd9gqaJ3"
   },
   "source": [
    "# **Visualization**\n",
    "There are several visualization options available in BERTopic, namely the visualization of topics, probabilities and topics over time. Topic modeling is, to a certain extent, quite subjective. Visualizations help understand the topics that were created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8c8LenB8Zyl"
   },
   "source": [
    "## Visualize Topics\n",
    "After having trained our `BERTopic` model, we can iteratively go through perhaps a hundred topic to get a good\n",
    "understanding of the topics that were extract. However, that takes quite some time and lacks a global representation.\n",
    "Instead, we can visualize the topics that were generated in a way very similar to\n",
    "[LDAvis](https://github.com/cpsievert/LDAvis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "S9qDqEHddgKq",
    "outputId": "3fddd5f1-194e-4708-a7dc-f0c5602c140a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"670px\"\n",
       "    height=\"670\"\n",
       "    src=\"iframe_figures/figure_11.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITB7bf6q8nWQ"
   },
   "source": [
    "## Visualize Topic Probabilities\n",
    "\n",
    "The variable `probabilities` that is returned from `transform()` or `fit_transform()` can\n",
    "be used to understand how confident BERTopic is that certain topics can be found in a document.\n",
    "\n",
    "To visualize the distributions, we simply call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "ypfI1-KHdmcX",
    "outputId": "4fd56127-4143-4cf7-d227-ef43725f1ad7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_distribution(probs[200], min_probability=0.015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHRTeSpl5JYB"
   },
   "source": [
    "## Visualize Topic Hierarchy\n",
    "\n",
    "The topics that were created can be hierarchically reduced. In order to understand the potential hierarchical structure of the topics, we can use scipy.cluster.hierarchy to create clusters and visualize how they relate to one another. This might help selecting an appropriate nr_topics when reducing the number of topics that you have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "ltmLFRR56a4X",
    "outputId": "0458e59c-30ce-4700-8dbf-0932afc63f1d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1020px\"\n",
       "    height=\"970\"\n",
       "    src=\"iframe_figures/figure_13.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_hierarchy(top_n_topics=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4spXl2_C6flq"
   },
   "source": [
    "## Visualize Terms\n",
    "\n",
    "We can visualize the selected terms for a few topics by creating bar charts out of the c-TF-IDF scores for each topic representation. Insights can be gained from the relative c-TF-IDF scores between and within topics. Moreover, you can easily compare topic representations to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "zpm9LsKW6mi5",
    "outputId": "1197affc-dde2-44c1-9ba7-c9fb36a1143c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1020px\"\n",
       "    height=\"520\"\n",
       "    src=\"iframe_figures/figure_14.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_barchart(top_n_topics=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCPdi6_z6sbT"
   },
   "source": [
    "## Visualize Topic Similarity\n",
    "Having generated topic embeddings, through both c-TF-IDF and embeddings, we can create a similarity matrix by simply applying cosine similarities through those topic embeddings. The result will be a matrix indicating how similar certain topics are to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "edzNhZuZ6wTr",
    "outputId": "e01231db-fe82-49d3-a96f-8135522d9b9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1020px\"\n",
       "    height=\"1020\"\n",
       "    src=\"iframe_figures/figure_15.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_heatmap(n_clusters=20, width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ak_CLR164mx"
   },
   "source": [
    "## Visualize Term Score Decline\n",
    "Topics are represented by a number of words starting with the best representative word. Each word is represented by a c-TF-IDF score. The higher the score, the more representative a word to the topic is. Since the topic words are sorted by their c-TF-IDF score, the scores slowly decline with each word that is added. At some point adding words to the topic representation only marginally increases the total c-TF-IDF score and would not be beneficial for its representation.\n",
    "\n",
    "To visualize this effect, we can plot the c-TF-IDF scores for each topic by the term rank of each word. In other words, the position of the words (term rank), where the words with the highest c-TF-IDF score will have a rank of 1, will be put on the x-axis. Whereas the y-axis will be populated by the c-TF-IDF scores. The result is a visualization that shows you the decline of c-TF-IDF score when adding words to the topic representation. It allows you, using the elbow method, the select the best number of words in a topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "7gT3Korh6-MX",
    "outputId": "5810f810-4633-425e-a7d2-3a1e9570639a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"520\"\n",
       "    src=\"iframe_figures/figure_16.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_term_rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D48ienfZrfP0"
   },
   "source": [
    "# **Topic Representation**\n",
    "After having created the topic model, you might not be satisfied with some of the parameters you have chosen. Fortunately, BERTopic allows you to update the topics after they have been created.\n",
    "\n",
    "This allows for fine-tuning the model to your specifications and wishes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4m3UMsw-Zxk"
   },
   "source": [
    "## Update Topics\n",
    "When you have trained a model and viewed the topics and the words that represent them,\n",
    "you might not be satisfied with the representation. Perhaps you forgot to remove\n",
    "stopwords or you want to try out a different `n_gram_range`. We can use the function `update_topics` to update\n",
    "the topic representation with new parameters for `c-TF-IDF`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KWm7B-FJ-iYW"
   },
   "outputs": [],
   "source": [
    "topic_model.update_topics(docs, n_gram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wf31gQavdtfG",
    "outputId": "b2cf3d47-f665-44fe-bbe0-c927e4d73363"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('game', 0.006527437691284437),\n",
       " ('team', 0.005588523235902932),\n",
       " ('he', 0.0052100527729702405),\n",
       " ('games', 0.004409689574255348),\n",
       " ('the', 0.0038883854698339186),\n",
       " ('players', 0.0037846348749340465),\n",
       " ('season', 0.0037344289250347894),\n",
       " ('was', 0.0037176187761276715),\n",
       " ('hockey', 0.0036580363788078587),\n",
       " ('year', 0.0036006153726642013)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(0)   # We select topic that we viewed before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9antKpdC91A-"
   },
   "source": [
    "## Topic Reduction\n",
    "We can also reduce the number of topics after having trained a BERTopic model. The advantage of doing so,\n",
    "is that you can decide the number of topics after knowing how many are actually created. It is difficult to\n",
    "predict before training your model how many topics that are in your documents and how many will be extracted.\n",
    "Instead, we can decide afterwards how many topics seems realistic:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5m4Nd7Us-Peg",
    "outputId": "2d442d39-5bc5-4e7f-c155-6e6c664f6714"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 10:22:58,013 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2024-03-01 10:23:09,547 - BERTopic - Topic reduction - Reduced number of topics from 226 to 60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bertopic._bertopic.BERTopic at 0x148c202da270>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.reduce_topics(docs, nr_topics=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXYJ745O-03Z"
   },
   "source": [
    "# **Search Topics**\n",
    "After having trained our model, we can use `find_topics` to search for topics that are similar\n",
    "to an input search_term. Here, we are going to be searching for topics that closely relate the\n",
    "search term \"vehicle\". Then, we extract the most similar topic and check the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAdiVYej-2i-",
    "outputId": "c107bd7d-1025-4d4d-b179-d007c7d16cd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 0, 21, 7]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_topics, similarity = topic_model.find_topics(\"vehicle\", top_n=5); similar_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q9paNa09d3Xy",
    "outputId": "545bbd07-8850-46d4-fdb7-28cb3d158b15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(71)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wekNoQNuUVoU"
   },
   "source": [
    "# **Model serialization**\n",
    "The model and its internal settings can easily be saved. Note that the documents and embeddings will not be saved. However, UMAP and HDBSCAN will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "nWUF1uxiSb_a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 10:25:11,652 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n",
      "/work/06562/lpearson/ls6/miniconda3/envs/llm/lib/python3.12/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning:\n",
      "\n",
      "Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "topic_model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "y_eHBI1jSb6i"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "my_model = BERTopic.load(\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eyImbal7lb8"
   },
   "source": [
    "# **Embedding Models**\n",
    "The parameter `embedding_model` takes in a string pointing to a sentence-transformers model, a SentenceTransformer, or a Flair DocumentEmbedding model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZKyW7NZpnEk"
   },
   "source": [
    "## Sentence-Transformers\n",
    "You can select any model from sentence-transformers here and pass it through BERTopic with embedding_model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "k7sPgNfzprbP"
   },
   "outputs": [],
   "source": [
    "topic_model = BERTopic(embedding_model=\"xlm-r-bert-base-nli-stsb-mean-tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vv7i1JTp62V"
   },
   "source": [
    "Or select a SentenceTransformer model with your own parameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Eh5qp58Hp7Ua"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b2ee0b1f354d63b5fd85912fe6f6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec55aaea9f94ac1af74d53107dc3d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a8988c83fa4fe799a569b0bef751da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1789fe71df845b0ae4b473d098400c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2102a24826764f1b8ee409cba6baedd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/550 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4ecff9c04f4f78810b92c63a4cf5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dfdb7dc0b441f480aeec19ccd58480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/450 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8aad570f1f0459a8ae21548572ddb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b80bd9a7ce4d98ad140faf1847b13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502a076abc9b494cadfc00e167905960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103ed046afc84a31a89bd533f42cba7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentence_model = SentenceTransformer(\"distilbert-base-nli-mean-tokens\", device=\"cpu\")\n",
    "topic_model = BERTopic(embedding_model=sentence_model, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoMc1W-x7-b5"
   },
   "source": [
    "Click [here](https://www.sbert.net/docs/pretrained_models.html) for a list of supported sentence transformers models.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python (llm)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

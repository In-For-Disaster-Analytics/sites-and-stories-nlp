{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac0f1330",
   "metadata": {},
   "source": [
    "## Llama Index and Llama 2 tutorial on Lonestar 6\n",
    "\n",
    "Llama2 is the Meta open source Large Language Model. LlamaIndex is a python library that connects data to the LLMs such as Llama2. This allows the user to quickly use their unstructured data as a basis for any chats or outputs. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4916970a",
   "metadata": {},
   "source": [
    "We've created a series of scripts to reduce the amount of coding needd to use these mdoels. So First we'll start by importing the libraries, and setting a few pieces of HTML.\n",
    "\n",
    "If your Kernel in the top right isn't already set to Python(LLM), go a head and change it. Click the Python Text and it will prompt you to change it. \n",
    "\n",
    "\n",
    "To Run a block of code, you will type shift + enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bbac77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/06659/wmobley\n"
     ]
    }
   ],
   "source": [
    "from LLM_location import *\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5085c503-a891-4463-b599-cc7973bd3310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".box_style{\n",
       "    height: auto;\n",
       "    background-color:green;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "\n",
    ".box_style{\n",
    "    height: auto;\n",
    "    background-color:green;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1ecfb9b",
   "metadata": {},
   "source": [
    "## Find your scratch directory\n",
    "When we load your text corpus into memory, we'll do it from sccratch. The next code block will show you where these files are saved if you need to access them later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e2053af",
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch = os.getenv('SCRATCH') \n",
    "print(scratch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a717aa0",
   "metadata": {},
   "source": [
    "## Initialize the Story Engine. \n",
    "Next, you'll initialize the story engine. This is the code that will do most of the work for you. The story engine will give you two prompts.\n",
    "\n",
    "1) The first is to select which model you want to use. Currently there are 4 models to choose from. \n",
    "\n",
    "- Something something why you should use each. \n",
    "\n",
    "The first section will have dropdown to select which model to use, and then click the load model button. \n",
    "\n",
    "2) The second task is to select your text corpus. On the left you will select the upload button. Pick a PDF, a HTML file, or a package of pdf's and htmls in a zip file. Upload those data. \n",
    "\n",
    "Once you've loaded the model and uploaded your corpus, select the file you want to use in the second tab. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cddcf1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bec7ef282e42c7bbf135e26136b924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(HBox(children=(Dropdown(description='Model:', index=3, options=('LLAMA2 7B', 'LLAMA2 7B CHâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "engine = Story_Engine()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19b4ec51",
   "metadata": {},
   "source": [
    "## Load the PDF documents \n",
    "Next you'll create the index of the files, and then the query enqine so that you can ask your questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e39fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Creating Index: Please make sure you chosen the model and the Corpus you want to use for the anlaysis.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Story_Engine' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m engine\u001b[38;5;241m.\u001b[39mcreate_index()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_query_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/06659/wmobley/ls6/sites-and-stories-nlp-jupyterenv/LLM_location.py:50\u001b[0m, in \u001b[0;36mStory_Engine.create_query_engine\u001b[0;34m(self, k, chunk_size)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_query_engine\u001b[39m(\u001b[38;5;28mself\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Better Explain Each of these steps. \u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_engine \u001b[38;5;241m=\u001b[39m CitationQueryEngine\u001b[38;5;241m.\u001b[39mfrom_args(\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m,\n\u001b[1;32m     51\u001b[0m     similarity_top_k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# here we can control how granular citation sources are, the default is 512\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     citation_chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     54\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Story_Engine' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "engine.create_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffbcf01-314d-418f-b8ef-19ec2265ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.create_query_engine()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2032029e",
   "metadata": {},
   "source": [
    "You can now start asking questions of your documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cab8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = engine.query(\"Who is the author?\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5ac23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fbe176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "response = query(\"What sampling approaches are used for estimating states of the world?\")\n",
    "print(( time.time()-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd2e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    " query(\"How computationally intensive are DMDU Processes?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9bb193",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query(\"what makes robust decision making difficult to understand? Please cite sources\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a479512",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query(\"what is an integrated modeling platform? Please provide source bibliography\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8511d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(response.source_nodes)):\n",
    "    display(response.source_nodes[i].node.metadata)\n",
    "    display(Markdown(response.source_nodes[i].node.get_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ad155",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query(\"What are the limitations when applying robust decision making to a problem.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d4d620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be308438",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(response.source_nodes)):\n",
    "    display(Markdown(response.source_nodes[i].node.get_text()));\n",
    "    display(response.source_nodes[i].node.metadata);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63997e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query(\"what are five features can improve user experience in  Decision making under deep uncertainty software, Please cite your sources\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b79ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query(\"what features can reduce the complexity of the decision making under deep uncertainty process? Please cite your sources\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query(\"Decision Making under deep uncertainty has a high learning curve, what could be added to a gui to reduce this learning curve? Please cite your sources\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb0ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(response.source_nodes)):\n",
    "    display(Markdown(response.source_nodes[i].node.get_text()));\n",
    "    display(response.source_nodes[i].node.metadata);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9646d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"\"\"What are the types of DMDU analyses used within the documents? \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"\"\"DMDU uses the following steps: 1) Problem Framing\n",
    "\t- Identify\n",
    "\t\t- objectives\n",
    "\t\t- constraints\n",
    "\t\t- major uncertainties\n",
    "\t\t- definition of success.\n",
    "2) Identify when the status quo starts to fail. \n",
    "\t- Simulate Business as Usual\n",
    "\t- Identify tipping points into a failing system\n",
    "\t\t- Need to identify rules for switching interventions\n",
    "3) Identify and measure interventions\n",
    "4) Explore Pathways from interventions\n",
    "5) Design Adaptive Plan\n",
    "\n",
    "\n",
    "Provide a list of triplets that identifies the algorithms used with each part.\\n\\n\\\n",
    "                          \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4170fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm_conda)\n",
   "language": "python",
   "name": "llm_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
